采用了scrapy-redis做了一个分布式的爬虫。最后用mysql存储数据。需要事先安装以及配置好redis以及mysql。

进入工程后，scrapy crawl myspider_58page运行这个命令就会开始爬页码直到最后结束。需要在redis中给出初始页码。

scrapy crawl myspider_58运行这个命令就会开始爬取具体的个人卖家的信息，会存储在相应的mysql表中。

上述2个爬虫都可以多开来达到多进程爬取的效果。

