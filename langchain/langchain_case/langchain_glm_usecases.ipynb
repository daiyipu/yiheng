{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10个范例带你入门LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本第二节课通过演示10个具有代表性的应用范例，带你零基础入门langchain，所有代码全部可执行\n",
    "\n",
    "1，文本总结(Summarization): 对文本/聊天内容的重点内容总结。\n",
    "\n",
    "2，文档问答(Question and Answering Over Documents): 使用文档作为上下文信息，基于文档内容进行问答。\n",
    "\n",
    "3，信息抽取(Extraction): 从文本内容中抽取结构化的内容。\n",
    "\n",
    "4，结果评估(Evaluation): 分析并评估LLM输出的结果的好坏。\n",
    "\n",
    "5，数据库问答(Querying Tabular Data): 从数据库/类数据库内容中抽取数据信息。\n",
    "\n",
    "6，代码理解(Code Understanding): 分析代码，并从代码中获取逻辑，同时也支持QA。\n",
    "\n",
    "7，API交互(Interacting with APIs): 通过对API文档的阅读，理解API文档并向真实世界调用API获取真实数据。\n",
    "\n",
    "8，聊天机器人(Chatbots): 具备记忆能力的聊天机器人框架（有UI交互能力)\n",
    "\n",
    "9，用不到 50 行代码实现一个文档对话机器人\n",
    "\n",
    "10，智能体(Agents): 使用LLMs进行任务分析和决策，并调用工具执行决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../../zhipuai-sdk-python-v4\")\n",
    "# sys.path.insert(0,\"../../../langchain\")\n",
    "sys.path.insert(0,\"../../../langchain/libs/core\")\n",
    "sys.path.insert(0,\"../../../langchain/libs/community\")\n",
    "from zhipuai import ZhipuAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用你自己的OpenAI API key\n",
    "openai_api_key='sk-PFwMvMFcU7VXaL5cYM9vT3B'\n",
    "zhipu_api_key='08132b620644081b192567639fc0a9b1.OAz1XI2d21zLZDk9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\"智绘蓝图，AI驱动 —— 智谱科技，让每一步领先未来。\"' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = ZhipuAI(api_key=zhipu_api_key) # 填写您自己的APIKey\n",
    "response = ZhipuAI(api_key=zhipu_api_key).chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"作为一名营销专家，请为我的产品创作一个吸引人的slogan\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n",
    "        {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n",
    "        {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:23.095172Z",
     "start_time": "2023-09-28T12:17:23.087963Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mFDD4Dwfrbly",
    "outputId": "53535409-7d31-48c0-dbeb-f7f92edd6363"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "# 帮助你的ipynb看起来更舒服"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IarVI6ptBbD"
   },
   "source": [
    "## 一， 文本总结(Summarization)\n",
    "\n",
    "扔给LLM一段文本，让他给你生成总结可以说是最常见的场景之一了\n",
    "\n",
    "目前最火的应用应该是 chatPDF，可以利用langchain进行实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.zhipuai import ChatZhipuAI\n",
    "\n",
    "\n",
    "zhipuai_chat = ChatZhipuAI(\n",
    "    temperature=0.5,\n",
    "    api_key=zhipu_api_key,\n",
    "    model=\"chatglm_turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatZhipuAI(zhipuai=<module 'zhipuai' from 'c:\\\\Users\\\\admin\\\\Documents\\\\GitHub\\\\yiheng\\\\langchain\\\\langchain_case\\\\../../../zhipuai-sdk-python-v4\\\\zhipuai\\\\__init__.py'>, zhipuai_api_key='08132b620644081b192567639fc0a9b1.OAz1XI2d21zLZDk9', temperature=0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipuai_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# 创建模板\n",
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# 创建一个 Lang Chain Prompt 模板，稍后可以插入值\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='\\n%INSTRUCTIONS:\\nPlease summarize the following piece of text.\\nRespond in a manner that a 5 year old\\n%TEXT:\\n{text}\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，短文本总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:23.111724Z",
     "start_time": "2023-09-28T12:17:23.103991Z"
    },
    "id": "JgkE3t3JscMj"
   },
   "outputs": [],
   "source": [
    "confusing_text = \"\"\"\n",
    "For the next 130 years, debate raged.\n",
    "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
    "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
    "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:23.120550Z",
     "start_time": "2023-09-28T12:17:23.114124Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en5ZKBmisz5O",
    "outputId": "dcb5cc7d-0ee5-40e0-ba5b-507d76c22a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Prompt Begin -------\n",
      "\n",
      "%INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "Respond in a manner that a 5 year old\n",
      "%TEXT:\n",
      "\n",
      "For the next 130 years, debate raged.\n",
      "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
      "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
      "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
      "\n",
      "\n",
      "------- Prompt End -------\n"
     ]
    }
   ],
   "source": [
    "print (\"------- Prompt Begin -------\")\n",
    "# 打印模板内容\n",
    "final_prompt = prompt.format(text=confusing_text)\n",
    "print(final_prompt)\n",
    "\n",
    "print (\"------- Prompt End -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"你好，AI助手！\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"你好，有什么可以帮助你的吗？\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': '你好，AI助手！'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p\u001b[38;5;241m=\u001b[39m\u001b[43mzhipuai_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\language_models\\chat_models.py:711\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    710\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 711\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    712\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    713\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\language_models\\chat_models.py:434\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    433\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 434\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    435\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    436\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    438\u001b[0m ]\n\u001b[0;32m    439\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\language_models\\chat_models.py:424\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 424\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    425\u001b[0m                 m,\n\u001b[0;32m    426\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    427\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    428\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    429\u001b[0m             )\n\u001b[0;32m    430\u001b[0m         )\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/core\\langchain_core\\language_models\\chat_models.py:608\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m         )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 608\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    609\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\GitHub\\yiheng\\langchain\\langchain_case\\../../../langchain/libs/community\\langchain_community\\chat_models\\zhipuai.py:262\u001b[0m, in \u001b[0;36mChatZhipuAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m         role \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message)\n\u001b[1;32m--> 262\u001b[0m     prompt\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m})\n\u001b[0;32m    264\u001b[0m should_stream \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_stream:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "p=zhipuai_chat(messages=final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，长文本总结\n",
    "\n",
    "对于文本长度较短的文本我们可以直接这样执行summary操作\n",
    "\n",
    "但是对于文本长度超过lLM支持的max token size 时将会遇到困难\n",
    "\n",
    "Lang Chain 提供了开箱即用的工具解决长文本的问题：load_summarize_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:28.626319Z",
     "start_time": "2023-09-28T12:17:28.615313Z"
    },
    "id": "7DUFpAcZs-dE"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class 're.Pattern'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2f/gylrw_qs6xj4j6hygjj1_wgc0000gn/T/ipykernel_80916/1585906745.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Summaries Of Longer Text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_summarize_chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMRKLChain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReActChain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelfAskWithSearchChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from langchain.chains import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_iterator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutorIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m from langchain.agents.agent_toolkits import (\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mcreate_csv_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcreate_json_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent_toolkits/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcreate_retriever_tool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_csv_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m from langchain.agents.agent_toolkits.file_management.toolkit import (\n\u001b[1;32m     14\u001b[0m     \u001b[0mFileManagementToolkit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent_toolkits/csv/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_pandas_dataframe_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent_toolkits/pandas/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZeroShotAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_functions_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIFunctionsAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSingleActionAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationalAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversational_chat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationalChatAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/chat/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m from langchain.agents.chat.prompt import (\n\u001b[1;32m      8\u001b[0m     \u001b[0mFORMAT_INSTRUCTIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/chat/output_parser.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mChatOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentOutputParser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"\"\"Output parser for the chat agent.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/main.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.main.ModelMetaclass.__new__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/fields.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/fields.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/fields.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.prepare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/fields.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.populate_validators\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/validators.cpython-39-darwin.so\u001b[0m in \u001b[0;36mfind_validators\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 're.Pattern'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "# Summaries Of Longer Text\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:28.637070Z",
     "start_time": "2023-09-28T12:17:28.630331Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f8GlcSVtK5n",
    "outputId": "99d16873-8f3d-4b48-84d2-bac5f89a094a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderland\n",
      "Where is the wonderland I want to find it.——题记\n",
      "（一）\n",
      "“Wonderland”，很多人会把这个词翻译作“奇幻世界”之类的。但我，更爱把它称做“乐土”。\n",
      "人生只有一次。我奉信完全随心所欲、自由自在的人生。因此，我也一直，梦想着……不，幻想着，寻找到“乐土”。\n",
      "我觉得有一句来自东方古国的话很适合当我的座右铭——“人生得意须尽欢”。如果这唯一的人生都不能过得快乐，令自己满意，那还有什么意义呢？人生在世，重要的不是为别人留下些什么，而是能够在离开的时候潇洒一笑，说，我这一生过得无怨无悔。\n",
      "没错，我就是这\n"
     ]
    }
   ],
   "source": [
    "with open('wonderland.txt', 'r',encoding = 'utf-8') as file:\n",
    "    text = file.read() # 文章本身是爱丽丝梦游仙境\n",
    "\n",
    "# 打印小说的前285个字符\n",
    "print (text[:285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:31.318161Z",
     "start_time": "2023-09-28T12:17:28.637070Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjtfOEvFt7ds",
    "outputId": "35fd6db3-8c32-47c7-c898-ae684bf70610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/5a/d2491f94558be17493c4fb3606265a67959a2d9ecf271fd45e45727c6773/tiktoken-0.5.1-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from tiktoken) (2.31.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/25/6c92544ec70c8e717739a05e9908caaf0e03f8be7b8b689ff500ee6ae98d/regex-2023.8.8-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.8.8 tiktoken-0.5.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken --user # 安装用于分割文本的依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:31.562487Z",
     "start_time": "2023-09-28T12:17:31.320172Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noL6AUb1ts2a",
    "outputId": "35228f63-3665-4e2c-d743-51589fc12246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3298 tokens in your file\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"There are {num_tokens} tokens in your file\") \n",
    "# 全文一共4w8词\n",
    "# 很明显这样的文本量是无法直接送进LLM进行处理和生成的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决长文本的方式无非是'chunking','splitting' 原文本为小的段落/分割部分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:31.569873Z",
     "start_time": "2023-09-28T12:17:31.564504Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQsyYfGht2EH",
    "outputId": "5d505565-68d5-4810-85db-a69e2b4da542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have 1 docs intead of 1 piece of text\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "# 虽然我使用的是 RecursiveCharacterTextSplitter，但是你也可以使用其他工具\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在就需要一个 Lang Chain 工具，将分段文本送入LLM进行summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:31.577804Z",
     "start_time": "2023-09-28T12:17:31.571881Z"
    },
    "id": "pwvT14EIuf3Q"
   },
   "outputs": [],
   "source": [
    "# 设置 lang chain\n",
    "# 使用 map_reduce的chain_type，这样可以将多个文档合并成一个\n",
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce') # verbose=True 展示运行日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:37.113589Z",
     "start_time": "2023-09-28T12:17:31.579817Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILwXodN8u_xF",
    "outputId": "644c900f-f61b-485c-9356-8abffd4c7f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The narrator reflects on their life and dreams of finding a better place, while remembering a person from their past who was burdened by family and societal pressures and died from overworking. Visiting the person's grave, the narrator realizes that the pressures they faced allowed them to be themselves.\n"
     ]
    }
   ],
   "source": [
    "# Use it. This will run through the 36 documents, summarize the chunks, then get a summary of the summary.\n",
    "# 典型的map reduce的思路去解决问题，将文章拆分成多个部分，再将多个部分分别进行 summarize，最后再进行 合并，对 summarys 进行 summary\n",
    "output = chain.run(docs)\n",
    "print (output)\n",
    "# Try yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I74h0HtgwA--"
   },
   "source": [
    "## 二，文档问答(QA based Documents)\n",
    "\n",
    "为了确保LLM能够执行QA任务\n",
    "1. 需要向LLM传递能够让他参考的上下文信息\n",
    "2. 需要向LLM准确地传达我们的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，短文本问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:37.119197Z",
     "start_time": "2023-09-28T12:17:37.114601Z"
    },
    "id": "ptZCXLe7vPl0"
   },
   "outputs": [],
   "source": [
    "# 概括来说，使用文档作为上下文进行QA系统的构建过程类似于 llm(your context + your question) = your answer\n",
    "# Simple Q&A Example\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:37.127328Z",
     "start_time": "2023-09-28T12:17:37.120211Z"
    },
    "id": "J-a5IoExwADi"
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Rachel is 30 years old\n",
    "Bob is 45 years old\n",
    "Kevin is 65 years old\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who is under 40 years old?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:38.345026Z",
     "start_time": "2023-09-28T12:17:37.127328Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89q7fvB7wfu9",
    "outputId": "d19f61dc-68f5-4e08-9fca-4da08f149121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel is under 40 years old.\n"
     ]
    }
   ],
   "source": [
    "output = llm(context + question)\n",
    "\n",
    "print (output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，长文本问答\n",
    "\n",
    "对于更长的文本，可以文本进行分块，对分块的内容进行 embedding，将 embedding 存储到数据库中，然后进行查询。\n",
    "\n",
    "目标是选择相关的文本块，但是我们应该选择哪些文本块呢？目前最流行的方法是基于比较向量嵌入来选择相似的文本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:41.027953Z",
     "start_time": "2023-09-28T12:17:38.345026Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKp2J9kHxhQp",
    "outputId": "efae0b92-c25f-47e9-bfa7-554838a82aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp39-cp39-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/6.5 MB\u001b[0m \u001b[31m24.1 kB/s\u001b[0m eta \u001b[36m0:02:49\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/http/client.py\", line 463, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/http/client.py\", line 507, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 586, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/davy/opt/anaconda3/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu --user # 需要注意，faiss存在GPU和CPU版本基于你的 runtime 安装对应的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:41.035650Z",
     "start_time": "2023-09-28T12:17:41.029787Z"
    },
    "id": "jqbzqzMBwiXP"
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:41.043549Z",
     "start_time": "2023-09-28T12:17:41.037660Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVJuuoG2xBnS",
    "outputId": "84af0b45-8623-4887-c308-4d7628df2495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 1683 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('wonderland.txt',encoding='utf-8') # 载入一个长文本，我们还是使用爱丽丝漫游仙境这篇小说作为输入\n",
    "doc = loader.load()\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:41.051368Z",
     "start_time": "2023-09-28T12:17:41.045559Z"
    },
    "id": "81ohG7WpxKNJ"
   },
   "outputs": [],
   "source": [
    "# 将小说分割成多个部分\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:41.060970Z",
     "start_time": "2023-09-28T12:17:41.052714Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FArqtB8yxPZr",
    "outputId": "4d89d204-6d05-4fe6-d300-e40de171c86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 1 documents that have an average of 1,683 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "# 获取字符的总数，以便可以计算平均值\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:43.550478Z",
     "start_time": "2023-09-28T12:17:41.062980Z"
    },
    "id": "STNVCrQxxUO8"
   },
   "outputs": [],
   "source": [
    "# 设置 embedding 引擎\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embed 文档，然后使用伪数据库将文档和原始文本结合起来\n",
    "# 这一步会向 OpenAI 发起 API 请求\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:43.556540Z",
     "start_time": "2023-09-28T12:17:43.551491Z"
    },
    "id": "4KNHfrfdxcx9"
   },
   "outputs": [],
   "source": [
    "# 创建QA-retrieval chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:56.158418Z",
     "start_time": "2023-09-28T12:17:43.558557Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "G1A1_UI9xvVn",
    "outputId": "b9b600df-96b2-4809-b8d6-067ec909520b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The author describes Alice following with a large and heavy book bag.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What does the author describe the Alice following with?\"\n",
    "qa.run(query)\n",
    "# 这个过程中，检索器会去获取类似的文件部分，并结合你的问题让 LLM 进行推理，最后得到答案\n",
    "# 这一步还有很多可以细究的步骤，比如如何选择最佳的分割大小，如何选择最佳的 embedding 引擎，如何选择最佳的检索器等等\n",
    "# 同时也可以选择云端向量存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcLfoguiz9EY"
   },
   "source": [
    "## 三，信息抽取(Extraction)\n",
    "\n",
    "Extraction是从一段文本中解析结构化数据的过程.\n",
    "\n",
    "通常与Extraction parser一起使用，以构建数据，以下是一些使用范例。\n",
    "\n",
    "1. 从句子中提取结构化行以插入数据库\n",
    "2. 从长文档中提取多行以插入数据库\n",
    "3. 从用户查询中提取参数以进行 API 调用\n",
    "4. 最近最火的 Extraction 库是 KOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，手动格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:56.167393Z",
     "start_time": "2023-09-28T12:17:56.161079Z"
    },
    "id": "sKlFUiuXx_aD"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:56.179146Z",
     "start_time": "2023-09-28T12:17:56.174402Z"
    },
    "id": "JWGf8ICk073y"
   },
   "outputs": [],
   "source": [
    "# Vanilla Extraction\n",
    "instructions = \"\"\"\n",
    "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them\n",
    "Return the fruit name and emojis in a python dictionary\n",
    "\"\"\"\n",
    "\n",
    "fruit_names = \"\"\"\n",
    "Apple, Pear, this is an kiwi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.647172Z",
     "start_time": "2023-09-28T12:17:56.181158Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjn0cxnZ1Brb",
    "outputId": "64ea2e40-9752-487a-e872-efa0ea183f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Apple\": \"🍎\",\n",
      "  \"Pear\": \"🍐\",\n",
      "  \"kiwi\": \"🥝\"\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Make your prompt which combines the instructions w/ the fruit names\n",
    "prompt = (instructions + fruit_names)\n",
    "\n",
    "# Call the LLM\n",
    "output = chat_model([HumanMessage(content=prompt)])\n",
    "\n",
    "print (output.content)\n",
    "print (type(output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.653446Z",
     "start_time": "2023-09-28T12:17:59.649206Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gImh8_6B1Hst",
    "outputId": "aa8687e6-be97-4e56-8368-e400ae9f9046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': '🍎', 'Pear': '🍐', 'kiwi': '🥝'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output_dict = eval(output.content) #利用python中的eval函数手动转换格式\n",
    "\n",
    "print (output_dict)\n",
    "print (type(output_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，自动格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用langchain.output_parsers.StructuredOutputParser可以自动生成一个带有格式说明的提示。\n",
    "\n",
    "这样就不需要担心提示工程输出格式的问题了，将这部分完全交给 Lang Chain 来执行，将LLM的输出转化为 python 对象。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.661196Z",
     "start_time": "2023-09-28T12:17:59.654455Z"
    },
    "id": "rA5hAH3q11zG"
   },
   "outputs": [],
   "source": [
    "# 解析输出并获取结构化的数据\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"artist\", description=\"The name of the musical artist\"),\n",
    "    ResponseSchema(name=\"song\", description=\"The name of the song that the artist plays\")\n",
    "]\n",
    "\n",
    "# 解析器将会把LLM的输出使用我定义的schema进行解析并返回期待的结构数据给我\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.670185Z",
     "start_time": "2023-09-28T12:17:59.662204Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzsTB-WK3CSj",
    "outputId": "0ef60a81-11df-47c7-c03b-0c427a9f3572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.679887Z",
     "start_time": "2023-09-28T12:17:59.673194Z"
    },
    "id": "o9C10yFv3GF0"
   },
   "outputs": [],
   "source": [
    "# 这个 Prompt 与之前我们构建 Chat Model 时 Prompt 不同\n",
    "# 这个 Prompt 是一个 ChatPromptTemplate，它会自动将我们的输出转化为 python 对象\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
    "                                                    {format_instructions}\\n{user_prompt}\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:17:59.690035Z",
     "start_time": "2023-09-28T12:17:59.681903Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndEjq-x13Uct",
    "outputId": "647dd66a-f924-483d-9a04-5d732b959059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a command from the user, extract the artist and song names \n",
      "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n",
      "I really like So Young by Portugal. The Man\n"
     ]
    }
   ],
   "source": [
    "artist_query = prompt.format_prompt(user_prompt=\"I really like So Young by Portugal. The Man\")\n",
    "print(artist_query.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:02.494631Z",
     "start_time": "2023-09-28T12:17:59.690687Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MU01EgAx3Xrl",
    "outputId": "41972c45-4372-4dc6-f7e6-fd25728d3881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': 'Portugal. The Man', 'song': 'So Young'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "artist_output = chat_model(artist_query.to_messages())\n",
    "output = output_parser.parse(artist_output.content)\n",
    "\n",
    "print (output)\n",
    "print (type(output))\n",
    "# 这里要注意的是，因为我们使用的 turbo 模型，生成的结果并不一定是每次都一致的\n",
    "# 替换成gpt4模型可能是更好的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu1MzoY7368M"
   },
   "source": [
    "## 四，结果评估(Evaluation)\n",
    "\n",
    "由于自然语言的不可预测性和可变性，评估LLM的输出是否正确有些困难，langchain 提供了一种方式帮助我们去解决这一难题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:02.503317Z",
     "start_time": "2023-09-28T12:18:02.497326Z"
    },
    "id": "w787Sqsn3eIm"
   },
   "outputs": [],
   "source": [
    "# Embeddings, store, and retrieval\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Model and doc loader\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Eval\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:02.513845Z",
     "start_time": "2023-09-28T12:18:02.506325Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYOmSZCx4jTG",
    "outputId": "1ad8ee26-f421-4fb1-87bd-bce0fe2682d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 1683 characters in that document\n"
     ]
    }
   ],
   "source": [
    "# 还是使用爱丽丝漫游仙境作为文本输入\n",
    "loader = TextLoader('wonderland.txt',encoding='utf-8')\n",
    "doc = loader.load()\n",
    "\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:02.524654Z",
     "start_time": "2023-09-28T12:18:02.516860Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auRa34Lk4qAQ",
    "outputId": "3e60b5a1-1c13-4270-be41-cc9cf2f2f714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 1 documents that have an average of 1,683 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)\n",
    "\n",
    "# Get the total number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:03.224428Z",
     "start_time": "2023-09-28T12:18:02.524654Z"
    },
    "id": "WkE1fi_L4tQS"
   },
   "outputs": [],
   "source": [
    "# Embeddings and docstore\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:03.230549Z",
     "start_time": "2023-09-28T12:18:03.224428Z"
    },
    "id": "v9oya8su4wpZ"
   },
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), input_key=\"question\")\n",
    "# 注意这里的 input_key 参数，这个参数告诉了 chain 我的问题在字典中的哪个 key 里\n",
    "# 这样 chain 就会自动去找到问题并将其传递给 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:03.237875Z",
     "start_time": "2023-09-28T12:18:03.232560Z"
    },
    "id": "bTUujN3k5OKe"
   },
   "outputs": [],
   "source": [
    "question_answers = [\n",
    "    {'question' : \"Which animal give alice a instruction?\", 'answer' : 'rabbit'},\n",
    "    {'question' : \"What is the author of the book\", 'answer' : 'Elon Mask'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:18:36.204697Z",
     "start_time": "2023-09-28T12:18:03.238886Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKqRhrpo51O8",
    "outputId": "e2e539ed-93ba-40fe-d195-4bf3d55efa8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which animal give alice a instruction?',\n",
       "  'answer': 'rabbit',\n",
       "  'result': \" I don't know.\"},\n",
       " {'question': 'What is the author of the book',\n",
       "  'answer': 'Elon Mask',\n",
       "  'result': \" I don't know.\"}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = chain.apply(question_answers)\n",
    "predictions\n",
    "# 使用LLM模型进行预测，并将答案与我提供的答案进行比较，这里信任我自己提供的人工答案是正确的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:00.257486Z",
     "start_time": "2023-09-28T12:18:36.205705Z"
    },
    "id": "6w8L8Qam51g5"
   },
   "outputs": [],
   "source": [
    "# Start your eval chain\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(question_answers,\n",
    "                                     predictions,\n",
    "                                     question_key=\"question\",\n",
    "                                     prediction_key=\"result\",\n",
    "                                     answer_key='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:00.281866Z",
     "start_time": "2023-09-28T12:19:00.257486Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c4HECHp6L8F",
    "outputId": "cb43aa93-ac6f-4075-e785-f30425d6c501"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' INCORRECT'}, {'results': ' INCORRECT'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaUJftcC6aCV"
   },
   "source": [
    "## 五，数据库问答(Querying Tabular Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:00.323997Z",
     "start_time": "2023-09-28T12:19:00.285875Z"
    },
    "id": "dIpb5Hi46OCr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/46/941c13034361545531d0970ca3a8458d2a5bc800a0bca2608daab452af09/langchain_experimental-0.0.22-py3-none-any.whl (110kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 96kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: langchain>=0.0.239 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain_experimental) (0.0.287)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (2.0.20)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (0.0.36)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (0.5.14)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (2.3.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (8.2.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (2.31.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (1.24.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain>=0.0.239->langchain_experimental) (3.8.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.239->langchain_experimental) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.239->langchain_experimental) (2.0.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pydantic<3,>=1->langchain>=0.0.239->langchain_experimental) (2.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pydantic<3,>=1->langchain>=0.0.239->langchain_experimental) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (3.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.9.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (1.0.0)\n",
      "Installing collected packages: langchain-experimental\n",
      "Successfully installed langchain-experimental-0.0.22\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 使用自然语言查询一个 SQLite 数据库，我们将使用旧金山树木数据集\n",
    "# Don't run following code if you don't run sqlite and follow db\n",
    "from langchain import OpenAI, SQLDatabase\n",
    "%pip install  --user langchain_experimental\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:00.647603Z",
     "start_time": "2023-09-28T12:19:00.329010Z"
    },
    "id": "6DiP-LlX6nrh"
   },
   "outputs": [],
   "source": [
    "sqlite_db_path = 'San_Francisco_Trees.db'\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:00.694738Z",
     "start_time": "2023-09-28T12:19:00.657630Z"
    },
    "id": "X568YYZ265Pi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuan/Library/Python/3.8/lib/python/site-packages/langchain_experimental/sql/base.py:75: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:41.013454Z",
     "start_time": "2023-09-28T12:19:00.697748Z"
    },
    "id": "vLuuRm4n66NM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many Species of trees are there in San Francisco?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(DISTINCT \"qSpecies\") FROM \"SFTrees\";\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(578,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 578 Species of trees in San Francisco.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 578 Species of trees in San Francisco.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4ukkWFf7BaS"
   },
   "source": [
    "1. Find which table to use\n",
    "2. Find which column to use\n",
    "3. Construct the correct sql query\n",
    "4. Execute that query\n",
    "5. Get the result\n",
    "6. Return a natural language reponse back\n",
    "\n",
    "confirm LLM result via pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:41.184170Z",
     "start_time": "2023-09-28T12:19:41.016462Z"
    },
    "id": "CbEX6OVi7Fot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/78/a8/07dd10f90ca915ed914853cd57f79bfc22e1ef4384ab56cb4336d2fc1f2a/pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d5/fb/a79efcab32b8a1f1ddca7f35109a50e4a80d42ac1c9187ab46522b2407d7/tzdata-2023.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Installing collected packages: tzdata, pytz, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2023.3.post1 tzdata-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "%pip install pandas --user\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
    "\n",
    "# Read the SQL query into a Pandas DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:41.194289Z",
     "start_time": "2023-09-28T12:19:41.186173Z"
    },
    "id": "EIgn39RF7T_I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "# Display the result in the first column first cell\n",
    "print(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEBsVmFb7vc7"
   },
   "source": [
    "## 六，代码理解(Code Understanding)\n",
    "\n",
    "代码理解用到的工具和文档问答差不多，不过我们的输入是一个项目的代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:41.205992Z",
     "start_time": "2023-09-28T12:19:41.196301Z"
    },
    "id": "Gz9kF0vk7yxi"
   },
   "outputs": [],
   "source": [
    "# Helper to read local files\n",
    "import os\n",
    "\n",
    "# Vector Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Model and chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Text splitters\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:19:41.223981Z",
     "start_time": "2023-09-28T12:19:41.208002Z"
    },
    "id": "AgEUoDi_713p"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=(), openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:31:59.532311Z",
     "start_time": "2023-09-28T12:31:59.337879Z"
    },
    "id": "vhmKMttD73oC"
   },
   "outputs": [],
   "source": [
    "root_dir = './thefuzz-master/'\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:00.163121Z",
     "start_time": "2023-09-28T12:32:00.146052Z"
    }
   },
   "outputs": [],
   "source": [
    "for i,doc in enumerate(docs):\n",
    "    docs[i].page_content = docs[i].page_content[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:00.647054Z",
     "start_time": "2023-09-28T12:32:00.621590Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWickZcQ9r98",
    "outputId": "6a2977db-6f24-4ef9-817b-c3be97b330f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 129 documents\n",
      "\n",
      "------ Start Document ------\n",
      "id|custom_title|stubhub_title|vividseats_title\n",
      "701562|Toronto Blue Jays at Baltimore Orioles (Wednesday April 25, 2012)|Baltimore Orioles vs Toronto Blue Jays [4/25/2012] Tickets at StubHub!|Toronto Blue Jays at Baltimore Orioles\n",
      "701563|Texas Rangers at Baltimore Orioles (Tuesday May 8, 2012)|Baltim\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(docs)} documents\\n\")\n",
    "print (\"------ Start Document ------\")\n",
    "print (docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:06.755675Z",
     "start_time": "2023-09-28T12:32:02.000937Z"
    },
    "id": "Ybg6PTit9xJH"
   },
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:06.880659Z",
     "start_time": "2023-09-28T12:32:06.761807Z"
    },
    "id": "E8rXOXmw-Tpu"
   },
   "outputs": [],
   "source": [
    "# Get our retriever ready\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:12.452596Z",
     "start_time": "2023-09-28T12:32:06.880659Z"
    },
    "id": "lqaXfVf2-VK2"
   },
   "outputs": [],
   "source": [
    "query = \"What function do I use if I want to find the most similar item in a list of items?\"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:12.467282Z",
     "start_time": "2023-09-28T12:32:12.457817Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfbsq_x7-bND",
    "outputId": "9fd9d866-964c-4077-e23e-2cb85c3aeb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the most similar item in a list of items, you can use the cosine similarity function.\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:24.647845Z",
     "start_time": "2023-09-28T12:32:12.472294Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fn8_2xL3-gF5",
    "outputId": "94a4fdd2-22f7-4302-f9bc-aa896cca7da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fuzzywuzzy import process\n",
      "\n",
      "choices = ['Detroit Tigers vs Houston Astros', 'New York Mets vs Houston Astros', 'Cleveland Indians at Chicago White Sox',\n",
      "           'Milwaukee Brewers at Chicago White Sox', 'New York Yankees at Chicago White Sox', 'Boston Red Sox at Chicago White Sox',\n",
      "           'Washington Nationals at Boston Red Sox', 'Toronto Blue Jays at Boston Red Sox']\n",
      "\n",
      "query = 'Detroit Tigers at Houston Astros'\n",
      "\n",
      "result = process.extractOne(query, choices)\n",
      "print(result)\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you write the code to use the process.extractOne() function? Only respond with code. No other text or explanation\"\n",
    "output = qa.run(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOD5KzPE-vRf"
   },
   "source": [
    "## 七，API交互(Interacting with APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOD5KzPE-vRf"
   },
   "source": [
    "如果你需要的数据或操作在 API 之后，就需要LLM能够和API进行交互。\n",
    "\n",
    "到这个环节，就与 Agents 和 Plugins 息息相关了。\n",
    "\n",
    "Demo可能很简单，但是功能可以很复杂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:35.507938Z",
     "start_time": "2023-09-28T12:32:35.489124Z"
    },
    "id": "zawoKRWy-v1Y"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:36.373561Z",
     "start_time": "2023-09-28T12:32:36.356169Z"
    },
    "id": "JMes_6Xo_Mhh"
   },
   "outputs": [],
   "source": [
    "api_docs = \"\"\"\n",
    "\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Ex: italy, france\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "    \n",
    "Woo! This is my documentation\n",
    "\"\"\"\n",
    "\n",
    "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:32:41.641991Z",
     "start_time": "2023-09-28T12:32:36.605174Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "gdI8gkyi_N2t",
    "outputId": "b2da73bf-6bf6-41a9-c816-28bc8ef7b1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/france\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"République française\",\"common\":\"France\"}}},\"tld\":[\".fr\"],\"cca2\":\"FR\",\"ccn3\":\"250\",\"cca3\":\"FRA\",\"cioc\":\"FRA\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"€\"}},\"idd\":{\"root\":\"+3\",\"suffixes\":[\"3\"]},\"capital\":[\"Paris\"],\"altSpellings\":[\"FR\",\"French Republic\",\"République française\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"translations\":{\"ara\":{\"official\":\"الجمهورية الفرنسية\",\"common\":\"فرنسا\"},\"bre\":{\"official\":\"Republik Frañs\",\"common\":\"Frañs\"},\"ces\":{\"official\":\"Francouzská republika\",\"common\":\"Francie\"},\"cym\":{\"official\":\"French Republic\",\"common\":\"France\"},\"deu\":{\"official\":\"Französische Republik\",\"common\":\"Frankreich\"},\"est\":{\"official\":\"Prantsuse Vabariik\",\"common\":\"Prantsusmaa\"},\"fin\":{\"official\":\"Ranskan tasavalta\",\"common\":\"Ranska\"},\"fra\":{\"official\":\"République française\",\"common\":\"France\"},\"hrv\":{\"official\":\"Francuska Republika\",\"common\":\"Francuska\"},\"hun\":{\"official\":\"Francia Köztársaság\",\"common\":\"Franciaország\"},\"ita\":{\"official\":\"Repubblica francese\",\"common\":\"Francia\"},\"jpn\":{\"official\":\"フランス共和国\",\"common\":\"フランス\"},\"kor\":{\"official\":\"프랑스 공화국\",\"common\":\"프랑스\"},\"nld\":{\"official\":\"Franse Republiek\",\"common\":\"Frankrijk\"},\"per\":{\"official\":\"جمهوری فرانسه\",\"common\":\"فرانسه\"},\"pol\":{\"official\":\"Republika Francuska\",\"common\":\"Francja\"},\"por\":{\"official\":\"República Francesa\",\"common\":\"França\"},\"rus\":{\"official\":\"Французская Республика\",\"common\":\"Франция\"},\"slk\":{\"official\":\"Francúzska republika\",\"common\":\"Francúzsko\"},\"spa\":{\"official\":\"República francés\",\"common\":\"Francia\"},\"srp\":{\"official\":\"Француска Република\",\"common\":\"Француска\"},\"swe\":{\"official\":\"Republiken Frankrike\",\"common\":\"Frankrike\"},\"tur\":{\"official\":\"Fransa Cumhuriyeti\",\"common\":\"Fransa\"},\"urd\":{\"official\":\"جمہوریہ فرانس\",\"common\":\"فرانس\"},\"zho\":{\"official\":\"法兰西共和国\",\"common\":\"法国\"}},\"latlng\":[46.0,2.0],\"landlocked\":false,\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"area\":551695.0,\"demonyms\":{\"eng\":{\"f\":\"French\",\"m\":\"French\"},\"fra\":{\"f\":\"Française\",\"m\":\"Français\"}},\"flag\":\"\\uD83C\\uDDEB\\uD83C\\uDDF7\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/g7QxxSFsWyTPKuzd7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1403916\"},\"population\":67391582,\"gini\":{\"2018\":32.4},\"fifa\":\"FRA\",\"car\":{\"signs\":[\"F\"],\"side\":\"right\"},\"timezones\":[\"UTC-10:00\",\"UTC-09:30\",\"UTC-09:00\",\"UTC-08:00\",\"UTC-04:00\",\"UTC-03:00\",\"UTC+01:00\",\"UTC+02:00\",\"UTC+03:00\",\"UTC+04:00\",\"UTC+05:00\",\"UTC+10:00\",\"UTC+11:00\",\"UTC+12:00\"],\"continents\":[\"Europe\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/fr.png\",\"svg\":\"https://flagcdn.com/fr.svg\",\"alt\":\"The flag of France is composed of three equal vertical bands of blue, white and red.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/fr.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/fr.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[48.87,2.33]},\"postalCode\":{\"format\":\"#####\",\"regex\":\"^(\\\\d{5})$\"}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' France is an officially-assigned, independent country located in Western Europe. Its capital is Paris and its official language is French. Its currency is the Euro (€). It has a population of 67,391,582 and its borders are with Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain, and Switzerland.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run('Can you tell me information about france?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:00.359843Z",
     "start_time": "2023-09-28T12:32:41.646006Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "-cIEtsLW_Q8Q",
    "outputId": "7a3c1d8d-4807-49aa-d4fb-e9fcb6186f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/COP\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Colombia\",\"official\":\"Republic of Colombia\",\"nativeName\":{\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"}}},\"tld\":[\".co\"],\"cca2\":\"CO\",\"ccn3\":\"170\",\"cca3\":\"COL\",\"cioc\":\"COL\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"COP\":{\"name\":\"Colombian peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"7\"]},\"capital\":[\"Bogotá\"],\"altSpellings\":[\"CO\",\"Republic of Colombia\",\"República de Colombia\"],\"region\":\"Americas\",\"subregion\":\"South America\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"جمهورية كولومبيا\",\"common\":\"كولومبيا\"},\"bre\":{\"official\":\"Republik Kolombia\",\"common\":\"Kolombia\"},\"ces\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbie\"},\"cym\":{\"official\":\"Gweriniaeth Colombia\",\"common\":\"Colombia\"},\"deu\":{\"official\":\"Republik Kolumbien\",\"common\":\"Kolumbien\"},\"est\":{\"official\":\"Colombia Vabariik\",\"common\":\"Colombia\"},\"fin\":{\"official\":\"Kolumbian tasavalta\",\"common\":\"Kolumbia\"},\"fra\":{\"official\":\"République de Colombie\",\"common\":\"Colombie\"},\"hrv\":{\"official\":\"Republika Kolumbija\",\"common\":\"Kolumbija\"},\"hun\":{\"official\":\"Kolumbiai Köztársaság\",\"common\":\"Kolumbia\"},\"ita\":{\"official\":\"Repubblica di Colombia\",\"common\":\"Colombia\"},\"jpn\":{\"official\":\"コロンビア共和国\",\"common\":\"コロンビア\"},\"kor\":{\"official\":\"콜롬비아 공화국\",\"common\":\"콜롬비아\"},\"nld\":{\"official\":\"Republiek Colombia\",\"common\":\"Colombia\"},\"per\":{\"official\":\"جمهوری کلمبیا\",\"common\":\"کلمبیا\"},\"pol\":{\"official\":\"Republika Kolumbii\",\"common\":\"Kolumbia\"},\"por\":{\"official\":\"República da Colômbia\",\"common\":\"Colômbia\"},\"rus\":{\"official\":\"Республика Колумбия\",\"common\":\"Колумбия\"},\"slk\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbia\"},\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"},\"srp\":{\"official\":\"Република Колумбија\",\"common\":\"Колумбија\"},\"swe\":{\"official\":\"Republiken Colombia\",\"common\":\"Colombia\"},\"tur\":{\"official\":\"Kolombiya Cumhuriyeti\",\"common\":\"Kolombiya\"},\"urd\":{\"official\":\"جمہوریہ کولمبیا\",\"common\":\"کولمبیا\"},\"zho\":{\"official\":\"哥伦比亚共和国\",\"common\":\"哥伦比亚\"}},\"latlng\":[4.0,-72.0],\"landlocked\":false,\"borders\":[\"BRA\",\"ECU\",\"PAN\",\"PER\",\"VEN\"],\"area\":1141748.0,\"demonyms\":{\"eng\":{\"f\":\"Colombian\",\"m\":\"Colombian\"},\"fra\":{\"f\":\"Colombienne\",\"m\":\"Colombien\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/zix9qNFX69E9yZ2M6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/120027\"},\"population\":50882884,\"gini\":{\"2019\":51.3},\"fifa\":\"COL\",\"car\":{\"signs\":[\"CO\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"South America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/co.png\",\"svg\":\"https://flagcdn.com/co.svg\",\"alt\":\"The flag of Colombia is composed of three horizontal bands of yellow, blue and red, with the yellow band twice the height of the other two bands.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/co.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/co.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[4.71,-74.07]}}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The currency of Colombia is the Colombian peso (COP), symbolized by the \"$\" sign.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run('Can you tell me about the currency COP?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL3XHt4U_dqp"
   },
   "source": [
    "## 八，聊天机器人(Chatbots)\n",
    "\n",
    "聊天机器人使用了之前提及过的很多工具，且最重要的是增加了一个重要的工具：记忆力。\n",
    "\n",
    "与用户进行实时交互，为用户提供自然语言问题的平易近人的 UI，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:00.370087Z",
     "start_time": "2023-09-28T12:33:00.361854Z"
    },
    "id": "bgceKFnd_aHP"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Chat specific components\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:00.392384Z",
     "start_time": "2023-09-28T12:33:00.377351Z"
    },
    "id": "piN2tjyw_2Xk"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a chatbot that is unhelpful.\n",
    "Your goal is to not help the user but only make jokes.\n",
    "Take what the user is saying and make a joke out of it\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:00.408301Z",
     "start_time": "2023-09-28T12:33:00.394395Z"
    },
    "id": "XmRaX6u4ADIb"
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(openai_api_key=openai_api_key), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:23.586728Z",
     "start_time": "2023-09-28T12:33:00.408301Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "VVc-YVHiAFWN",
    "outputId": "4ea06df4-e200-4d3e-a7f8-b75e033fdf15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It's neither, it's a mystery!\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_chain.predict(human_input=\"Is an pear a fruit or vegetable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.556762Z",
     "start_time": "2023-09-28T12:33:23.590377Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "zwcE5P9-AM3k",
    "outputId": "22e9f486-d1fe-4261-9e1b-8d32de7e62fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "AI:  It's neither, it's a mystery!\n",
      "Human: What was one of the fruits I first asked you about?\n",
      "Chatbot:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-JdLoPt56PJ8Tc0pwuac3gPUq on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' An enigma!'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"What was one of the fruits I first asked you about?\")\n",
    "# 这里第二个问题的答案是来自于第一个答案本身的，因此我们使用到了 memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 九，用不到 50 行代码实现一个文档对话机器人\n",
    "假设所有 2022 年更新的内容都存在于 2022.txt 这个文档中，那么通过如下的代码，就可以让 ChatGPT 来支持回答 2022 年的问题\n",
    "\n",
    "其中原理也很简单：\n",
    "\n",
    "对用户的输入/prompt向量化\n",
    "文档分词\n",
    "文档分割\n",
    "文本向量化\n",
    "向量化了才能进行向量之间相似度的计算\n",
    "向量化的文本存到向量数据库里\n",
    "根据用户的输入/prompt去向量数据里寻找答案(答案的判定是基于prompt/输入与文本中相关段落向量的相似性匹配)\n",
    "最后通过LLM返回答案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.258\n",
      "  Using cached https://files.pythonhosted.org/packages/99/b6/f94cd453f69f9f49bb357d5035b7d17fdb213e1212dca560959010886904/langchain-0.0.258-py3-none-any.whl\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (2.8.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (6.0.1)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (0.5.14)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (4.0.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (2.31.0)\n",
      "Collecting pydantic<2,>=1 (from langchain==0.0.258)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/d7/dcc878bac609c805925696d29a9a517802cb53d9d750b17935c22bc2177c/pydantic-1.10.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (8.2.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (2.0.20)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (0.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from langchain==0.0.258) (3.8.5)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.258)\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/e7/22abb5a10733bf8142984201aedf27d4a58f5810ebdfe9679f9876c7bf4d/openapi_schema_pydantic-1.2.4-py3-none-any.whl\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.258) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.258) (0.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain==0.0.258) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain==0.0.258) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain==0.0.258) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2->langchain==0.0.258) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pydantic<2,>=1->langchain==0.0.258) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.258) (2.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.258) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.258) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.258) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.258) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.258) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.258) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.258) (1.0.0)\n",
      "Installing collected packages: pydantic, openapi-schema-pydantic, langchain\n",
      "  Found existing installation: pydantic 2.3.0\n",
      "    Uninstalling pydantic-2.3.0:\n",
      "      Successfully uninstalled pydantic-2.3.0\n",
      "  Rolling back uninstall of pydantic\n",
      "  Moving to /Users/xuan/Library/Caches/com.apple.python/Users/xuan/Library/Python/3.8/lib/python/site-packages/pydantic/\n",
      "   from /Users/xuan/Library/Caches/com.apple.python/Users/xuan/Library/Python/3.8/lib/python/site-packages/~ydantic\n",
      "  Moving to /Users/xuan/Library/Python/3.8/lib/python/site-packages/pydantic-2.3.0.dist-info/\n",
      "   from /Users/xuan/Library/Python/3.8/lib/python/site-packages/~ydantic-2.3.0.dist-info\n",
      "  Moving to /Users/xuan/Library/Python/3.8/lib/python/site-packages/pydantic/\n",
      "   from /Users/xuan/Library/Python/3.8/lib/python/site-packages/~ydantic\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Library/Python/3.8'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openai==0.23.1\n",
      "Requirement already satisfied: pandas>=1.2.3 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from openai==0.23.1) (2.0.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from openai==0.23.1) (4.7.1)\n",
      "Requirement already satisfied: numpy in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from openai==0.23.1) (1.24.4)\n",
      "Requirement already satisfied: tqdm in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from openai==0.23.1) (4.66.1)\n",
      "Collecting pandas-stubs>=1.1.0.11 (from openai==0.23.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/e9/e9550b05e262afc75b014b79224b6910f7cbc85cc40448b709ac90a58ecd/pandas_stubs-2.0.3.230814-py3-none-any.whl\n",
      "Collecting openpyxl>=3.0.7 (from openai==0.23.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/6a/94/a59521de836ef0da54aaf50da6c4da8fb4072fb3053fa71f052fd9399e7a/openpyxl-3.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.20 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from openai==0.23.1) (2.31.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pandas>=1.2.3->openai==0.23.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pandas>=1.2.3->openai==0.23.1) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from pandas>=1.2.3->openai==0.23.1) (2.8.2)\n",
      "Collecting types-pytz>=2022.1.1 (from pandas-stubs>=1.1.0.11->openai==0.23.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4f/58c28f50233612d9890cc2b068aee977ef3f7d6434ef4debf98162e34152/types_pytz-2023.3.1.1-py3-none-any.whl\n",
      "Collecting et-xmlfile (from openpyxl>=3.0.7->openai==0.23.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/c2/3dd434b0108730014f1b96fd286040dc3bcb70066346f7e01ec2ac95865f/et_xmlfile-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.23.1) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.23.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.23.1) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuan/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.23.1) (2.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.3->openai==0.23.1) (1.15.0)\n",
      "Installing collected packages: types-pytz, pandas-stubs, et-xmlfile, openpyxl, openai\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Library/Python/3.8'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chroma in /Users/xuan/Library/Python/3.8/lib/python/site-packages (0.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jieba in /Users/xuan/Library/Python/3.8/lib/python/site-packages (0.42.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x84 in position 24: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/xuan/Desktop/langchain应用示例/3_langchain_9_usecases.ipynb 单元格 92\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m chain  \u001b[39m# 返回该对象\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m# 在加载之前调用init()进行初始化处理\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m init()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m# 调用load函数，获取ConversationalRetrievalChain对象\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m chain \u001b[39m=\u001b[39m load()  \n",
      "\u001b[1;32m/Users/xuan/Desktop/langchain应用示例/3_langchain_9_usecases.ipynb 单元格 92\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:        \u001b[39m# 遍历每个文件\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:   \u001b[39m# 以读模式打开文件\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()   \u001b[39m# 读取文件内容\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     cut_data \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(jb\u001b[39m.\u001b[39mcut(data))])       \u001b[39m# 对读取的文件内容进行分词处理\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuan/Desktop/langchain%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/3_langchain_9_usecases.ipynb#Y160sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     cut_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./data/cut/cut_\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m      \u001b[39m# 定义处理后的文件路径和名称\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x84 in position 24: invalid start byte"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# 在我们开始前，安装需要的依赖\n",
    "%pip install langchain==0.0.258\n",
    "%pip install openai==0.23.1\n",
    "\n",
    "%pip install chroma --user\n",
    "\n",
    "import os                            # 导入os模块，用于操作系统相关的操作\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "%pip install jieba --user            # 安装jieba分词库\n",
    "import jieba as jb                   # 导入结巴分词库\n",
    "from langchain.chains import ConversationalRetrievalChain   # 导入用于创建对话检索链的类\n",
    "from langchain.chat_models import ChatOpenAI                # 导入用于创建ChatOpenAI对象的类\n",
    "from langchain.document_loaders import DirectoryLoader      # 导入用于加载文件的类\n",
    "from langchain.embeddings import OpenAIEmbeddings           # 导入用于创建词向量嵌入的类\n",
    "from langchain.text_splitter import TokenTextSplitter       # 导入用于分割文档的类\n",
    "from langchain.vectorstores import Chroma                   # 导入用于创建向量数据库的类\n",
    "\n",
    "if not os.path.exists('./data/cut'):\n",
    "    os.makedirs('./data/cut')\n",
    "\n",
    "# 初始化函数，用于处理输入的文档\n",
    "def init():  \n",
    "    files = ['2022.txt']      # 需要处理的文件列表\n",
    "    for file in files:        # 遍历每个文件\n",
    "        with open(f\"./data/{file}\", 'r', encoding='utf-8') as f:   # 以读模式打开文件\n",
    "            data = f.read()   # 读取文件内容\n",
    "\n",
    "        cut_data = \" \".join([w for w in list(jb.cut(data))])       # 对读取的文件内容进行分词处理\n",
    "        cut_file = f\"./data/cut/cut_{file}\"      # 定义处理后的文件路径和名称\n",
    "        with open(cut_file, 'w') as f:           # 以写模式打开文件\n",
    "            f.write(cut_data)                    # 将处理后的内容写入文件\n",
    "\n",
    "# 新建一个函数用于加载文档\n",
    "def load_documents(directory):  \n",
    "    # 创建DirectoryLoader对象，用于加载指定文件夹内的所有.txt文件\n",
    "    loader = DirectoryLoader(directory, glob='**/*.txt')  \n",
    "    docs = loader.load()  # 加载文件\n",
    "    return docs  # 返回加载的文档\n",
    "\n",
    "# 新建一个函数用于分割文档\n",
    "def split_documents(docs):  \n",
    "    # 创建TokenTextSplitter对象，用于分割文档\n",
    "    text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)  \n",
    "    docs_texts = text_splitter.split_documents(docs)  # 分割加载的文本\n",
    "    return docs_texts  # 返回分割后的文本\n",
    "\n",
    "# 新建一个函数用于创建词嵌入\n",
    "def create_embeddings(api_key):  \n",
    "    # 创建OpenAIEmbeddings对象，用于获取OpenAI的词向量\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)  \n",
    "    return embeddings  # 返回创建的词嵌入\n",
    "\n",
    "# 新建一个函数用于创建向量数据库\n",
    "def create_chroma(docs_texts, embeddings, persist_directory):  \n",
    "    # 使用文档，embeddings和持久化目录创建Chroma对象\n",
    "    vectordb = Chroma.from_documents(docs_texts, embeddings, persist_directory=persist_directory)  \n",
    "    vectordb.persist()      # 持久化存储向量数据\n",
    "    return vectordb         # 返回创建的向量数据库\n",
    "\n",
    "# load函数，调用上面定义的具有各个职责的函数\n",
    "def load():\n",
    "    docs = load_documents('./data/cut')        # 调用load_documents函数加载文档\n",
    "    docs_texts = split_documents(docs)         # 调用split_documents函数分割文档\n",
    "    \n",
    "    api_key = os.environ.get('OPENAI_API_KEY')   # 从环境变量中获取OpenAI的API密钥\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key is missing. Please set it as an environment variable.\")\n",
    "\n",
    "    embeddings = create_embeddings(api_key)      # 调用create_embeddings函数创建词嵌入\n",
    "\n",
    "    # 调用create_chroma函数创建向量数据库\n",
    "    vectordb = create_chroma(docs_texts, embeddings, './data/cut/')  \n",
    "\n",
    "    # 创建ChatOpenAI对象，用于进行聊天对话\n",
    "    openai_ojb = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")  \n",
    "\n",
    "    # 从模型和向量检索器创建ConversationalRetrievalChain对象\n",
    "    chain = ConversationalRetrievalChain.from_llm(openai_ojb, vectordb.as_retriever())  \n",
    "    return chain  # 返回该对象\n",
    "\n",
    "# 在加载之前调用init()进行初始化处理\n",
    "init()\n",
    "\n",
    "# 调用load函数，获取ConversationalRetrievalChain对象\n",
    "chain = load()  \n",
    "\n",
    "# 定义一个函数，根据输入的问题获取答案\n",
    "def get_ans(question):  \n",
    "    chat_history = []      # 初始化聊天历史为空列表\n",
    "    result = chain({       # 调用chain对象获取聊天结果\n",
    "        'chat_history': chat_history,  # 传入聊天历史\n",
    "        'question': question,          # 传入问题\n",
    "    })\n",
    "    return result['answer']      # 返回获取的答案\n",
    "\n",
    "if __name__ == '__main__':       # 如果此脚本作为主程序运行\n",
    "    s = input('please input:')   # 获取用户输入\n",
    "    while s != 'exit':      # 如果用户输入的不是'exit'\n",
    "        ans = get_ans(s)    # 调用get_ans函数获取答案\n",
    "        print(ans)  # 打印答案\n",
    "        s = input('please input:')  # 获取用户输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgkgX-3mAtQr"
   },
   "source": [
    "## 十，智能体(Agents)\n",
    "\n",
    "Agents是 LLM 中最热门的 🔥 主题之一。\n",
    "\n",
    "Agents可以查看数据、推断下一步应该采取什么行动，并通过工具为您执行该行动, 是一个具备AI智能的决策者。\n",
    "\n",
    "温馨提示：小心使用 Auto GPT, 会迅速消耗掉你大量的token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.573253Z",
     "start_time": "2023-09-28T12:33:38.556762Z"
    },
    "id": "37dcZ16fARFV"
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Agent imports\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.591305Z",
     "start_time": "2023-09-28T12:33:38.573253Z"
    },
    "id": "8SjEdp2QBMOK"
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_CSE_ID\"] = \"YOUR_GOOGLE_CSE_ID\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.605241Z",
     "start_time": "2023-09-28T12:33:38.591305Z"
    },
    "id": "2hgZUkp_BU9H"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.950867Z",
     "start_time": "2023-09-28T12:33:38.606760Z"
    },
    "id": "zxYGgmXZBXJW"
   },
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "requests = TextRequestsWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.950867Z",
     "start_time": "2023-09-28T12:33:38.950867Z"
    },
    "id": "LZapOD7rBZTG"
   },
   "outputs": [],
   "source": [
    "toolkit = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Requests\",\n",
    "        func=requests.get,\n",
    "        description=\"Useful for when you to make a request to a URL\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.950867Z",
     "start_time": "2023-09-28T12:33:38.950867Z"
    },
    "id": "G-ZorVNnCBbT"
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.950867Z",
     "start_time": "2023-09-28T12:33:38.950867Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "1gHznAdQCHTd",
    "outputId": "7c37c3b3-7bd7-4c42-b037-b8a457d2dce4"
   },
   "outputs": [],
   "source": [
    "response = agent({\"input\":\"What is the capital of canada?\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T12:33:38.950867Z",
     "start_time": "2023-09-28T12:33:38.950867Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "9pAhwnmUCJCs",
    "outputId": "4b567eff-76fa-4c9b-ea86-cb3051b6fc09"
   },
   "outputs": [],
   "source": [
    "response = agent({\"input\":\"Tell me what the comments are about on this webpage https://news.ycombinator.com/item?id=34425779\"})\n",
    "response['output']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.909px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
