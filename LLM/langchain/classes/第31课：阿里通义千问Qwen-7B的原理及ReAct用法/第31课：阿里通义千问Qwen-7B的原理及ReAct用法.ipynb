{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d030c2de",
   "metadata": {},
   "source": [
    "## Qwen-7B\n",
    "\n",
    "项目地址：https://github.com/QwenLM/Qwen-7B/blob/main/README_CN.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f836be",
   "metadata": {},
   "source": [
    "## Qwen-7B-Chat\n",
    "\n",
    "### 微调数据构成\n",
    "微调数据由指令对话、安全防护以及服务响应三方面构成。指令对话数据涵盖写作、问答、头脑风暴、计划、内容理解、摘要等等基本任务；安全防护数据旨在防止模型输出不恰当的内容；而服务响应数据是Qwen较之其他Chat类模型更为特殊的一部分，目的在于让模型学习到如何在适当的时机调用合适的外部系统来推进相关工作。\n",
    "\n",
    "此外，考虑到微调数据都是对话轮的形式，所以Qwen项目组用ChatML标准对数据进行格式化。\n",
    "\n",
    "### 数据格式：ChatML\n",
    "\n",
    "ChatML官方简述：https://github.com/openai/openai-python/blob/main/chatml.md\n",
    "\n",
    "ChatML是OpenAI提出的一种结构化文本格式，其特点在于以相对结构化的形式标明了角色及相应内容，以官方文档的例子来说明：\n",
    "\n",
    "```shell\n",
    "# 经典版（Qwen使用的是这个）\n",
    "<|im_start|>system\n",
    "You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\n",
    "Knowledge cutoff: 2021-09-01\n",
    "Current date: 2023-03-01<|im_end|>\n",
    "<|im_start|>user\n",
    "How are you<|im_end|>\n",
    "<|im_start|>assistant\n",
    "I am doing well!<|im_end|>\n",
    "<|im_start|>user\n",
    "How are you now?<|im_end|>\n",
    "\n",
    "# 新版（list of dicts）\n",
    "[\n",
    " {\"token\": \"<|im_start|>\"},\n",
    " \"system\\nYou are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-01\",\n",
    " {\"token\": \"<|im_end|>\"}, \"\\n\", {\"token\": \"<|im_start|>\"},\n",
    " \"user\\nHow are you\",\n",
    " {\"token\": \"<|im_end|>\"}, \"\\n\", {\"token\": \"<|im_start|>\"},\n",
    " \"assistant\\nI am doing well!\",\n",
    " {\"token\": \"<|im_end|>\"}, \"\\n\", {\"token\": \"<|im_start|>\"},\n",
    " \"user\\nHow are you now?\",\n",
    " {\"token\": \"<|im_end|>\"}, \"\\n\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125d79c",
   "metadata": {},
   "source": [
    "## 特殊用法-ReAct Prompting\n",
    "得益于Qwen-7B-Chat在微调阶段使用了服务响应数据进行训练，Qwen-7B-Chat具备了一定的工具调用能力，这使得直接使用Qwen-7B-Chat进行ReAct也能取得不错的效果。\n",
    "\n",
    "### ReAct\n",
    "ReAct可以理解为“Reasoning and Acting”，即“推理与行动”，是一种在模型推理侧提升输出准确性的技术。关于Reasoning方面，COT对模型推理效果的提升有目共睹，但在相关研究中表明，其链路中涉及的知识也将对输出结果产生一定的影响，在模型本身性能不足够推理出正确结果、也无法调用外部世界知识的情况下，会产生事实幻觉和错误传播的问题。因此，ReAct在COT的基础之上，引入了“Action”操作，即通过Few-Shot Prompt来引导模型生成推理内容及与外界交互获取知识的动作，通过逐步推理与动作交互，将外部知识以动态的方式融入进COT链路中，以此来提高模型最终输出结果的准确性。\n",
    "\n",
    "我们可以简单理解为，在对模型进行提问的时候，不要求模型直接就推断出结果，我们倾向于让模型使用COT的思路一点点推理，推理的过程中如果需要外部知识的介入，那么模型就会先调用外部工具来获取外部知识，然后将外部知识补充进上下文中继续推理，如此往复，直到推理出最终的结果。基于缜密且真实的上下文得到的结果，自然准确性会高不少。\n",
    "\n",
    "整体的思想源自于这篇论文：Synergizing Reasoning and Acting in Language Models \n",
    "\n",
    "https://arxiv.org/pdf/2210.03629.pdf\n",
    "\n",
    "### Qwen官方ReAct文档示例\n",
    "https://github.com/QwenLM/Qwen-7B/blob/main/examples/react_prompt.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d31f6f",
   "metadata": {},
   "source": [
    "## ReAct实例演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fab124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定好Qwen-7B-Chat模型文件路径\n",
    "model_file_path = \"./Qwen-7B-Chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d8a03f-5beb-4123-8f58-facb7875ef69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import json5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea59bf6-15b2-408f-be35-ba30151fbd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query = '准确计算3.5+1.5*3+3/2.55的结果'\n",
    "# query = '职工张三的生日是在今年10月份吗？'\n",
    "query = '职工张三的生日是在今年10月份吗？现在是2月份，距离张三的生日还有几个月？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dfe22ed-7cb8-4f2f-bb2c-63f89ae19e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# （注册）定义工具\n",
    "TOOLS = [\n",
    "    {\n",
    "        'name_for_human':\n",
    "        '企业员工数据库',\n",
    "        'name_for_model':\n",
    "        'database',\n",
    "        'description_for_model':\n",
    "        '企业员工数据库储存有我司员工个人基本信息，通过输入员工名字可返回其个人信息。',\n",
    "        'parameters': [{\n",
    "            'name': 'database_query',\n",
    "            'description': '员工名字，所需查阅信息的员工姓名',\n",
    "            'required': True,\n",
    "            'schema': {\n",
    "                'type': 'string'\n",
    "            },\n",
    "        }],\n",
    "    },\n",
    "    {\n",
    "        'name_for_human':\n",
    "        '计算器',\n",
    "        'name_for_model':\n",
    "        'calculator',\n",
    "        'description_for_model':\n",
    "        '计算器是一个用于进行数值计算的工具，输入具体的数值计算公式文本，返回其运算结果',\n",
    "        'parameters': [{\n",
    "            'name': 'calculate',\n",
    "            'description': '数值计算公式文本，包含了需要进行计算的数值和运算符',\n",
    "            'required': True,\n",
    "            'schema': {\n",
    "                'type': 'string'\n",
    "            },\n",
    "        }],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fb7cb9-fad4-4c1c-8ca1-c18ba27dc616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class database:\n",
    "    def __init__(self):\n",
    "        # 数据库存有员工基本信息\n",
    "        self.database = {\n",
    "            \"李四\": {\n",
    "                \"性别\": \"女\",\n",
    "                \"生日\": \"10月3日\",\n",
    "                \"职位\": \"画师\"\n",
    "            },\n",
    "            \"张三\": {\n",
    "                \"性别\": \"男\",\n",
    "                \"生日\": \"5月5日\",\n",
    "                \"职位\": \"业务员\"\n",
    "            },\n",
    "            \"王五\": {\n",
    "                \"性别\": \"男\",\n",
    "                \"生日\": \"12月19日\",\n",
    "                \"职位\": \"业务经理\"\n",
    "            }\n",
    "        }\n",
    "    def database_query(self, name):\n",
    "        # 输入姓名返回员工信息\n",
    "        return self.database.get(name, \"查无此人\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c4c0a3-c3ce-46f0-81e7-77f332a64cb9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'性别': '女', '生日': '10月3日', '职位': '画师'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = database()\n",
    "db.database_query(\"李四\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c345c8-f3fb-4cfd-a5f5-dc83d0e8dd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class calculator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def calculate(self, formula_str):\n",
    "        return eval(formula_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acefd5c-4866-4f71-a249-6430e8ab5ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal = calculator()\n",
    "cal.calculate(\"1+5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e1b13b-2625-4b9e-81ad-4d699ef386b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_latest_plugin_call(text: str):\n",
    "    \"\"\"\n",
    "    text: 模型的ReAct输出内容\n",
    "    return: 工具方法名字, 工具方法入参\n",
    "    \"\"\"\n",
    "    i = text.rfind('\\nAction:')\n",
    "    j = text.rfind('\\nAction Input:')\n",
    "    k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j:  # If the text has `Action` and `Action input`,\n",
    "        if k < j:  # but does not contain `Observation`,\n",
    "            # then it is likely that `Observation` is ommited by the LLM,\n",
    "            # because the output text may have discarded the stop word.\n",
    "            text = text.rstrip() + '\\nObservation:'  # Add it back.\n",
    "            k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j < k:\n",
    "        plugin_name = text[i + len('\\nAction:'):j].strip()\n",
    "        plugin_args = text[j + len('\\nAction Input:'):k].strip()\n",
    "        return plugin_name, plugin_args\n",
    "    return '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c7ab3a-6b05-4440-a1be-c70675ba9c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义react prompt模板\n",
    "\n",
    "TOOL_DESC = \"\"\"{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters} Format the arguments as a JSON object.\"\"\"\n",
    "\n",
    "REACT_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tool_descs}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c008af-9563-45d5-9958-65873393983b",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "database: Call this tool to interact with the 企业员工数据库 API. What is the 企业员工数据库 API useful for? 企业员工数据库储存有我司员工个人基本信息，通过输入员工名字可返回其个人信息。 Parameters: [{\"name\": \"database_query\", \"description\": \"员工名字，所需查阅信息的员工姓名\", \"required\": true, \"schema\": {\"type\": \"string\"}}] Format the arguments as a JSON object.\n",
      "\n",
      "calculator: Call this tool to interact with the 计算器 API. What is the 计算器 API useful for? 计算器是一个用于进行数值计算的工具，输入具体的数值计算公式文本，返回其运算结果 Parameters: [{\"name\": \"calculate\", \"description\": \"数值计算公式文本，包含了需要进行计算的数值和运算符\", \"required\": true, \"schema\": {\"type\": \"string\"}}] Format the arguments as a JSON object.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [database,calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 职工张三的生日是在今年10月份吗？现在是2月份，距离张三的生日还有几个月？\n"
     ]
    }
   ],
   "source": [
    "# 定义真正传入模型的react prompt\n",
    "tool_descs = []\n",
    "tool_names = []\n",
    "for info in TOOLS:\n",
    "    tool_descs.append(\n",
    "        TOOL_DESC.format(\n",
    "            name_for_model=info['name_for_model'],\n",
    "            name_for_human=info['name_for_human'],\n",
    "            description_for_model=info['description_for_model'],\n",
    "            parameters=json.dumps(\n",
    "                info['parameters'], ensure_ascii=False),\n",
    "        )\n",
    "    )\n",
    "    tool_names.append(info['name_for_model'])\n",
    "tool_descs = '\\n\\n'.join(tool_descs)\n",
    "tool_names = ','.join(tool_names)\n",
    "\n",
    "prompt = REACT_PROMPT.format(tool_descs=tool_descs, tool_names=tool_names, query=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77d90d05-c902-4246-a577-ba0c6ddf3197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00966644287109375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 8,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fed71437d4d4781a22adb5a6b4c1b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "\n",
    "# 请注意：分词器默认行为已更改为默认关闭特殊token攻击防护。\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_file_path, trust_remote_code=True)\n",
    "\n",
    "# 打开bf16精度，A100、H100、RTX3060、RTX3070等显卡建议启用以节省显存\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-7B-Chat\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "# 打开fp16精度，V100、P100、T4等显卡建议启用以节省显存\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-7B-Chat\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "# 使用CPU进行推理，需要约32GB内存\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-7B-Chat\", device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "# 默认使用自动模式，根据设备自动选择精度\n",
    "model = AutoModelForCausalLM.from_pretrained(model_file_path, device_map=\"auto\", trust_remote_code=True).eval()\n",
    "\n",
    "# 可指定不同的生成长度、top_p等相关超参\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_file_path, trust_remote_code=True)\n",
    "# print(model.generation_config.top_p)\n",
    "# print(model.generation_config.temperature)\n",
    "\n",
    "\n",
    "# 设置stop_word\n",
    "react_stop_words = [\n",
    "    # tokenizer.encode('Observation'),  # [37763, 367]\n",
    "    tokenizer.encode('Observation:'),  # [37763, 367, 25]\n",
    "    tokenizer.encode('Observation:\\n'),  # [37763, 367, 510]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d710c619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (core_attention_flash): FlashSelfAttention()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae68c30-75cd-44c9-9af0-f03a0ad2e0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 需要查询数据库中的员工信息，才能回答问题，应该使用database工具。\n",
      "Action: database\n",
      "Action Input: {\"database_query\": \"张三\"}\n",
      "Observation:\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(\n",
    "    tokenizer, prompt, history=None,\n",
    "    stop_words_ids=react_stop_words  # 此接口用于增加 stop words\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e24f639d-bf47-4de8-86fe-64f289225252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工具返回: {'status_code': 200, 'result': {'性别': '男', '生日': '5月5日', '职位': '业务员'}}\n",
      "------------------------------------------------------------\n",
      "Thought: 需要查询数据库中的员工信息，才能回答问题，应该使用database工具。\n",
      "Action: database\n",
      "Action Input: {\"database_query\": \"张三\"}\n",
      "Observation: {'status_code': 200, 'result': {'性别': '男', '生日': '5月5日', '职位': '业务员'}}\n"
     ]
    }
   ],
   "source": [
    "# v2\n",
    "\n",
    "# 从模型的react输出中提取“工具方法”及“工具方法入参”\n",
    "tool_cfg = parse_latest_plugin_call(response)\n",
    "\n",
    "# 根据“工具方法”及“工具方法入参”调用工具并取得返回结果\n",
    "result_dict = {\"status_code\":200}\n",
    "tools_msg = [TOOL for TOOL in TOOLS if tool_cfg[0] in TOOL['name_for_model']]\n",
    "for tool_msg in tools_msg:\n",
    "    for tool_cfg_each in tool_cfg[1:]:\n",
    "        tool_dict_each = json5.loads(tool_cfg_each)\n",
    "        for k, v in tool_dict_each.items():\n",
    "            if k in [tool_p['name'] for tool_p in tool_msg['parameters']]:\n",
    "                tool_inst = eval(tool_cfg[0])()\n",
    "                tool_func = getattr(tool_inst, k)\n",
    "                result = tool_func(v)\n",
    "                result_dict[\"result\"] = result\n",
    "# 工具返回结果\n",
    "print(\"工具返回: {}\".format(result_dict))\n",
    "print(\"---\"*20)\n",
    "\n",
    "# 将工具返回结果与前文进行拼接，将在后续传入模型继续进行生成\n",
    "response += \" \" + str(result_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2065515e-2bdb-46e9-9ae8-217443dd5d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 张三的生日是在5月份，现在是2月份，距离张三的生日还有3个月。\n",
      "Final Answer: 张三的生日是在5月份，现在是2月份，距离张三的生日还有3个月。\n"
     ]
    }
   ],
   "source": [
    "# 将带有工具返回结果（事实知识）的内容传给模型进一步得到结果\n",
    "response, history = model.chat(\n",
    "    tokenizer, response, history=history,\n",
    "    stop_words_ids=react_stop_words  # 此接口用于增加 stop words\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
