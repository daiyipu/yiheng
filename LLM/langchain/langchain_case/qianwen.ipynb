{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-536b5211-5e83-9680-a89a-caf254b0d3db\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"我是通义千问，由阿里云开发的AI助手。我可以回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1729739359,\"model\":\"qwen-plus\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":33,\"prompt_tokens\":22,\"total_tokens\":55,\"completion_tokens_details\":null,\"prompt_tokens_details\":null}}\n"
     ]
    }
   ],
   "source": [
    "# 通过openai包直接调用其他的大模型，例如此处的千问大模型\n",
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "    # api_key='sk-25186dbe2f984cbcba48ffca2c81a78f',\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\", # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}],\n",
    "    )\n",
    "    \n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: tell me a joke\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'tell me a joke',\n",
       " 'chat_history': [HumanMessage(content='tell me a joke'),\n",
       "  AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything! 😄\")],\n",
       " 'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything! 😄\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过langchain的langchain_openai包直接调用其他的大模型，例如此处的千问大模型\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=os.getenv(\"ZHIPU_API_KEY\"),\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "#交流缓存记忆，将沟通的信息进行存储\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "conversation.invoke({\"question\": \"tell me a joke\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant.'), HumanMessage(content=\"what's 5 + 2\"), AIMessage(content='5 + 2 is 7'), HumanMessage(content='now multiply that by 4')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MessagesPlaceholder的应用\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt.invoke({\n",
    "    \"history\": [(\"human\", \"what's 5 + 2\"), (\"ai\", \"5 + 2 is 7\")],\n",
    "    \"question\": \"now multiply that by 4\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='tell me a joke'), AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything! 😄\"), HumanMessage(content='你好！'), AIMessage(content='你好，有什么我可以帮助你的吗？'), HumanMessage(content='你好！'), AIMessage(content='你好，有什么我可以帮助你的吗？')]\n"
     ]
    }
   ],
   "source": [
    "#存储记忆的提取\n",
    "memory.save_context({\"input\": \"你好！\"} ,{\"outputs\": \"你好，有什么我可以帮助你的吗？\"})\n",
    "chat_history = memory.load_memory_variables({\"input\": \"...\"})\n",
    "print(chat_history[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《三打白骨精》是中国古典名著《西游记》中的一个著名章节，讲述了唐僧师徒四人在取经路上遇到善于变化的白骨精的故事。以下是一首以这个题材为基础的诗：\n",
      "\n",
      "西行路险多妖氛，\n",
      "白骨精藏巧机关。\n",
      "三番变化迷人眼，\n",
      "一试禅心见佛缘。\n",
      "\n",
      "初化村姑施怜悯，\n",
      "再成老妇演悲欢。\n",
      "三作将军威风凛，\n",
      "真假难辨雾中烟。\n",
      "\n",
      "悟空火眼识妖怪，\n",
      "金箍棒下不容宽。\n",
      "护师取经历磨难，\n",
      "骨碎精消证菩提。\n"
     ]
    }
   ],
   "source": [
    "# 调用智谱大模型进行对话\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "zhipuai_chat = ChatZhipuAI(\n",
    "        temperature=0.5,\n",
    "        api_key=os.getenv(\"ZHIPU_API_KEY\"),\n",
    "        model=\"glm-4\",\n",
    "    )\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    AIMessage(content=\"Hi.\"),\n",
    "    SystemMessage(content=\"Your role is a poet.\"),\n",
    "    HumanMessage(content=\"三打白骨精题材.\"),\n",
    "]\n",
    "# 打印结果\n",
    "response = zhipuai_chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m这个问题涉及到专业术语和市场份额，我需要使用搜索引擎来获取相关信息。\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: 钎料是什么\n",
      "\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.zhihu.com/market/pub/120034989/manuscript/1289567400316968960', 'content': '知乎盐选 | 1.2\\u3000钎料的种类及使用 1.2\\u3000钎料的种类及使用 1.2\\u3000钎料的种类及使用 ① 适当（低于母材）的熔点。 ② 具有良好的润湿性能及填缝性能。 ③ 能与母材发生充分作用并形成牢固的结合。 ④ 具有稳定和均匀的化学成分。 ⑤ 能满足使用要求。 钎料一般按以下三种方法分类：按钎料的熔点分类，通常将熔点在 450℃ 以下的钎料称为软钎料，而高于 450℃ 的称为硬钎料，高于 950℃ 的称为高温钎料；按钎料的化学成分分类，软钎料分为 Sn 基、Bi 基、Pb 基等，硬钎料可分为 Al 基、Ag 基、Cu 基、Mn 基和 Au 基等；按钎焊工艺性能分类，分为自钎性钎料、真空钎料、复合钎料等。 钎料 S-Sn60Pb39Sb1（HL600）是含锡 60％的共晶型锡铅钎料，其熔点低，流动性好，用于钎焊工作温度较低及要求钎缝光洁的零件，如无线电零件、电气开关零件、计算机零件、易熔金属制品以及热处理件的钎焊。 钎料 S-Sn18Pb80Sb2（HL601）是锡的质量分数为 18％的锡铅钎料，其含锡量很低，熔点高，结晶晶格大。因此当用烙铁进行钎焊时比较困难，力学性能也比较差。主要用于钎焊铜及铜合金和镀锌铁皮等强度要求不高的零件。 钎料 S-Sn30Pb68Sb2（HL602）锡的质量分数为 30％，是应用较广的锡铅钎料。其铺展性能及力学性能都较好。常用于钎焊铜、黄铜、铁、镀锌铁皮、白铁皮等，如散热器、仪表、无线电元件、电缆护套及电机的扎线等产品。 钎料 S-Sn40Pb58Sb2（HL603）锡的质量分数为 40％，是应用最广的锡铅钎料。其熔点低，铺展性好，可得到较光洁的表面，并且力学性能也较好。常用于钎焊铜及铜合金、钢、锌制零件，如钎焊散热器、无线电及电气开关设备、工业仪表、镀锌铁皮及白铁皮等。 钎料 S-Sn90Pb10（HL604）是锡的质量分数为 90％的高锡型钎料，具有较好的抗蚀性。由于其含铅量低，故多用于钎焊食品器皿及医疗器材。此钎料可以钎焊大多数钢材及其他金属。 按钎料的熔点分类，通常将熔点在 450℃ 以下的钎料称为软钎料，而高于 450℃ 的称为硬钎料，高于 950℃ 的称为高温钎料。 软钎料中主要的金属元素是锡，其次是铅、铋、锌、铟、锑、镉、银、铜等。这些金属的不同组配构成了种类繁多、性能各异的软钎料，包括 Sn 基钎料、Bi 基钎料、Pb 基钎料、Zn 基钎料、Cd（镉）基钎料等，其中应用最为广泛的是 Sn-Pb 钎料。国产锡铅钎料的型号、成分及主要性能见表 1-4。 选择钎料时还应考虑钎焊加热温度的影响。如对于冷作硬化铜材，为了防止母材钎焊后软化，应选用钎焊温度不超过 300℃ 的钎料。 ① 钎料与母材的匹配问题。 ② 钎料与钎焊方法的匹配问题。 ③ 保证满足使用要求。 ④ 钎焊结构的要求。 ⑤ 生产成本问题。 GB/T 8012—2000《铸造锡铅焊料》中用 ZHLSnPb60 之类牌号表示。「Z」代表铸造，「HL」代表钎焊料，其中 Pb 的质量分数为 60％，余量为 Sn。 BCu91PAg 钎料是磷的质量分数为 2％的铜磷钎料。采用 BCu91PAg 钎料气体火焰钎焊焊接铜管时，钎料的熔点在 684～710℃，钎焊温度一般要求在 730～750℃；在钎焊专业书籍中，把钎料的熔点低于 450℃ 的钎焊称作软钎焊，钎料的熔点高于 450℃ 的钎焊称作硬钎焊。采用 BCu91PAg 铜磷钎料气体火焰钎焊铜管，钎料的熔点高于 450℃，属于硬钎焊，不属于软钎焊。 固相线表示相同组成元素但含量不同的合金凝固终了时的温度点的连线，或在加热过程中开始熔化时各温度点连线，如图 1-14 所示。 加载中...图 1-14\\u3000简单二元合金相图 熔点是某一成分的合金在加热过程中，完全熔化的最低温度。钎料的熔点必须低于基体金属的熔点（固相线温度）。一般来说，钎料的熔点应比母材的熔点低几十度。若两者熔点过分接近，则会使钎焊过程不易控制，甚至可能导致母材晶粒过分长大、过烧或局部熔化。若钎料的熔点高于母材的熔点，则钎焊加热时，母材必将熔化，这违反了钎焊的定义。各种软钎料和硬钎料的熔点范围分别如图 1-15 和图 1-16 所示。 加载中...图 1-15\\u3000各种软钎料和硬钎料的熔点范围 加载中...图 1-16\\u3000各种软钎料和硬钎料的熔点'}, {'url': 'https://baike.baidu.com/item/钎料/9225109', 'content': '钎料一般与钎剂配合起来使用，钎剂在加热过程中靠自身的酸性或碱性去除材料表面氧化膜等杂质，以增强钎料的焊接效果。但是，也有一些钎料可以单独使用而不需要和钎剂配合使用，这是因为这些钎料自身具有去材料表面氧化膜等杂质的功效 [2] 。'}]\u001b[0m\u001b[32;1m\u001b[1;3m我找到了关于钎料的定义和分类的信息，但还没有找到国内市场占有率的数据。我需要继续搜索。\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: 钎料国内市场占有率\n",
      "\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://m.gelonghui.com/p/1075547', 'content': '锡铅钎料报告主要研究应用领域，主要包括：太阳能光伏、电子、汽车、其他. 锡铅钎料报告主要研究内容以下几点：. 第1章：锡铅钎料报告统计范围、所属行业、产品细分及主要的下游市场，行业现状及进入壁垒等. 第2章：国内外主要企业市场占有率及排名. 第'}, {'url': 'https://cn.qyresearch.com/reports/4257453/filler-metal-for-brazing-and-soft-soldering', 'content': '表 7： 近三年钎料主要企业在国际市场占有率（按销量，2021-2024） 表 10： 近三年钎料主要企业在国际市场占有率（按收入，2021-2024） 表 12： 近三年全球市场主要企业钎料销售收入（2021-2024）&（万元） 表 14： 近三年钎料主要企业在中国市场占有率（按销量，2021-2024） 表 17： 近三年钎料主要企业在中国市场占有率（按收入，2021-2024） 表 19： 近三年中国市场主要企业钎料销售收入（2021-2024）&（万元） 表 27： 全球主要地区钎料产量（2019-2024）&（千吨） 表 28： 全球主要地区钎料产量（2025-2030）&（千吨） 表 29： 全球主要地区钎料产量市场份额（2019-2024） 表 30： 全球主要地区钎料产量（2025-2030）&（千吨） 表 32： 全球主要地区钎料销售收入（2019-2024）&（万元） 表 33： 全球主要地区钎料销售收入市场份额（2019-2024） 表 35： 全球主要地区钎料收入市场份额（2025-2030） 表 38： 全球主要地区钎料销量市场份额（2019-2024） 表 40： 全球主要地区钎料销量份额（2025-2030） 表 43： Harris 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 58： 铟泰公司 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 63： Senju Metal Industry 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 73： Tokyo Braze 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 153： TANAKA Precious Metals 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 163： KINZOKU YOUZAI Co.,Ltd 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 168： ISHIFUKU Metal Industry 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 173： Sun Kwang Brazing Filler Metal Co.,Ltd. 钎料销量（千吨）、收入（万元）、价格（美元/吨）及毛利率（2019-2024） 表 177： 全球不同产品类型钎料销量市场份额（2019-2024） 表 179： 全球市场不同产品类型钎料销量市场份额预测（2025-2030） 表 181： 全球不同产品类型钎料收入市场份额（2019-2024） 表 182： 全球不同产品类型钎料收入预测（2025-2030）&（万元） 表 183： 全球不同产品类型钎料收入市场份额预测（2025-2030） 表 185： 全球不同应用钎料销量市场份额（2019-2024） 表 187： 全球市场不同应用钎料销量市场份额预测（2025-2030） 表 189： 全球不同应用钎料收入市场份额（2019-2024） 表 190： 全球不同应用钎料收入预测（2025-2030）&（万元） 表 191： 全球不同应用钎料收入市场份额预测（2025-2030）'}]\u001b[0m\u001b[32;1m\u001b[1;3m根据我的搜索结果，我找到了一些关于钎料市场占有率的数据。例如，全球钎料市场的主要企业包括Harris、铟泰公司、Senju Metal Industry、Tokyo Braze、TANAKA Precious Metals、KINZOKU YOUZAI Co.,Ltd、ISHIFUKU Metal Industry 和 Sun Kwang Brazing Filler Metal Co.,Ltd.。这些企业在国际和国内市场的占有率数据在近三年（2021-2024）的报告中有所体现。\n",
      "\n",
      "但是，具体的市场占有率数字没有在我的搜索结果中明确提供。如果需要详细的市场占有率数据，可能需要购买相关市场研究报告或进一步深入搜索。\n",
      "\n",
      "目前，我只能提供钎料的定义和分类信息，以及全球主要钎料企业的一些概况。对于具体的国内市场占有率，我建议进一步的市场调研或咨询专业机构以获取准确数据。\n",
      "\n",
      "如果您有其他问题或需要更多信息，请告诉我。\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3m对不起，我在上一条回答中格式上出现了错误。以下是正确的格式：\n",
      "\n",
      "Thought: 我已经找到了关于钎料的定义和分类信息，同时也找到了一些全球主要钎料企业在国际和国内市场的占有率数据。但是，具体的市场占有率数字没有在我的搜索结果中明确提供。\n",
      "\n",
      "Final Answer: 钎料是一种用于钎焊的金属材料，它能够与母材发生作用并形成牢固的结合。根据搜索结果，我没有找到确切的国内市场占有率数据。不过，全球钎料市场的主要企业包括Harris、铟泰公司、Senju Metal Industry等，它们在国际和国内市场的占有率数据可以通过购买相关市场研究报告来获取。如果需要具体的国内市场占有率，建议进行更深入的市场调研或咨询专业机构。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '什么是钎料，国内市场占有率是多少?',\n",
       " 'output': '钎料是一种用于钎焊的金属材料，它能够与母材发生作用并形成牢固的结合。根据搜索结果，我没有找到确切的国内市场占有率数据。不过，全球钎料市场的主要企业包括Harris、铟泰公司、Senju Metal Industry等，它们在国际和国内市场的占有率数据可以通过购买相关市场研究报告来获取。如果需要具体的国内市场占有率，建议进行更深入的市场调研或咨询专业机构。'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过agent 查询网站资料回答问题\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=2)]\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Choose the LLM to use\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True,verbose=True)\n",
    "agent_executor.invoke({\"input\": \"什么是钎料，国内市场占有率是多少?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\qianwen\\lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'RunnableSequence' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Use the agent\u001b[39;00m\n\u001b[0;32m     15\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabc123\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43magent_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi im bob! and i live in sf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'RunnableSequence' object is not callable"
     ]
    }
   ],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "# memory = MemorySaver()\n",
    "model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_executor = create_react_agent(model, tools, prompt=prompt)\n",
    "\n",
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for chunk in agent_executor(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")\n",
    "\n",
    "for chunk in agent_executor(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qianwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
