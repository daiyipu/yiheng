{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-0ba80660-aa2c-988c-9630-18c344440c46\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"我是Qwen，由阿里云研发的超大规模语言模型。我能够生成各种类型的文本，如文章、故事、诗歌等，并能根据不同的场景和需求进行调整和优化。我可以帮助人们更高效地创作内容，提供创意支持，或是在学习和工作中给予协助。有什么我可以帮到你的吗？\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1729480411,\"model\":\"qwen-plus\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":68,\"prompt_tokens\":32,\"total_tokens\":100,\"completion_tokens_details\":null,\"prompt_tokens_details\":null}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "    # api_key='sk-25186dbe2f984cbcba48ffca2c81a78f',\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\", # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}],\n",
    "    )\n",
    "    \n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'crewai.tasks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TaskOutput\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tongyi\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent, Task, Crew, Process\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'crewai.tasks'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from crewai.tasks.task_output import TaskOutput\n",
    "from langchain_community.llms import Tongyi\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "# from authentications import DASHSCOPE_API_KEY\n",
    "\n",
    "# CrewAI核心概念：https://github.com/joaomdmoura/crewAI/tree/main/docs/core-concepts\n",
    "# - Agent：一个具有特定职能和目标的个体，它被分配到特定的任务（Task）上，并执行该任务。\n",
    "# - Task：Agent被分配到的任务，Agent执行该任务。\n",
    "# - Crew：Agent和Task的容器，是Agent和Task的调度中心。\n",
    "\n",
    "# DashScope API Key\n",
    "DASHSCOPE_API_KEY=\"DASHSCOPE_API_KEY\"\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "# langchain模型实例\n",
    "llm = Tongyi(type=llm, input_value={'model_name': 'qwen-max'}, input_type=dict)\n",
    "\n",
    "\n",
    "def callback_func(output: TaskOutput) -> None:\n",
    "    md_content = f\"<p>{output.raw_output}</p>\"\n",
    "    with open(file=\"./story.md\", mode=\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_content)\n",
    "    return\n",
    "\n",
    "\n",
    "# 创建Agent：编剧\n",
    "screenwriter = Agent(\n",
    "    # 角色、职能：决定了任务分配的优先级\n",
    "    role=\"编剧\",\n",
    "    # 个体目标：对决策过程有参考意义\n",
    "    goal=\"使用中文通过生动的描述、深刻的情感表达将提供的主题扩写为引人入胜的故事。\",\n",
    "    # 角色背景：丰富设定，加强输出风格\n",
    "    backstory=\"\"\"早期先锋编剧，擅长各种风格的表现手法撰写剧本故事，在气氛营造、剧情表达以及人物塑造上表现出超一流的水准。\"\"\",\n",
    "    # 是否打印运行日志\n",
    "    verbose=True,\n",
    "    # 是否允许将任务委托给其他agent\n",
    "    allow_delegation=False,\n",
    "    # llm实例：langchain统一封装好的llm实例\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# 创建Agent：评论家\n",
    "critic = Agent(\n",
    "    role=\"评论家\",\n",
    "    goal=\"确保故事内容、行文风格、故事类型的一致性，并通过中文进行表达。\",\n",
    "    backstory=\"\"\"资深电影学教授，总是能捕捉到市场的需求和期待，对故事中的叙事结构甚至是隐喻都有深入了解，善于发现故事中的情节漏洞和一些不易察觉的错误。\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# 创建Agent：策划\n",
    "master = Agent(\n",
    "    role=\"策划\",\n",
    "    goal=\"使用中文进行沟通，跟进整个故事的创作过程，管理编剧与评论家之间的协作，确保最终所产出的故事能达到高水准，并且呈现出最终的、详细的完整剧本。\",\n",
    "    backstory=\"\"\"经验老到的游戏叙事设计师，擅长使用高水平的情节框架与叙事细节调动读者的共情能力，使得读者获得沉浸式体验。\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "在任何人的任何信息（包括DNA数据、记忆）都能够被统一数据化存储并监管的时代，一个名为“遗忘自由”的无政府主义乌托邦运动出现了，其使命是争取“被遗忘”的权利，组织成员认为事物有被遗忘的可能，才显得其更加有存在的意义。\n",
    "\"\"\"\n",
    "\n",
    "# 用户提供剧作主题\n",
    "user_input = input(\n",
    "    \"请提供一个剧本的主题: \"\n",
    ")\n",
    "\n",
    "# 创建Task\n",
    "story_task = Task(\n",
    "    # 对任务的描述、指令\n",
    "    description=f\"基于该主题使用中文撰写一个电影剧本: {user_input}\",\n",
    "    # 用以完成任务的Agent\n",
    "    agent=master,\n",
    "    # 对任务完成情况的详细描述，即任务所追求的目标\n",
    "    expected_output=\"一篇包含有数幕故事情节的电影剧本。\",\n",
    "    # 可处理Task输出的回调函数\n",
    "    callback=callback_func,\n",
    ")\n",
    "\n",
    "# 创建Crew\n",
    "story_crew = Crew(\n",
    "    # 可供协作完成任务的Agent列表\n",
    "    agents=[screenwriter, critic, master],\n",
    "    # 需要被执行的Task列表\n",
    "    tasks=[story_task],\n",
    "    # 是否打印运行日志\n",
    "    verbose=False,\n",
    "    # 工作流策略：sequential/hierarchical\n",
    "    process=Process.sequential,\n",
    "    language=\"Chinese\",\n",
    ")\n",
    "\n",
    "# 执行Crew\n",
    "story_output = story_crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StructuredTool' from 'langchain.tools' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StructuredTool\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StructuredTool' from 'langchain.tools' (unknown location)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "# import langchain_core.tools.convert as tlc\n",
    "# import langchain_core.tools  as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FieldInfo' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m stop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m。\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 假设Tongyi类有一个方法来生成文本\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 输出生成的文本\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    951\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    780\u001b[0m                 prompts,\n\u001b[0;32m    781\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    782\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    783\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    784\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    785\u001b[0m             )\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_community\\llms\\tongyi.py:260\u001b[0m, in \u001b[0;36mTongyi._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_to_generation(generation)])\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m    262\u001b[0m         completion \u001b[38;5;241m=\u001b[39m generate_with_retry(\u001b[38;5;28mself\u001b[39m, prompt\u001b[38;5;241m=\u001b[39mprompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_community\\llms\\tongyi.py:361\u001b[0m, in \u001b[0;36mTongyi._invocation_params\u001b[1;34m(self, stop, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invocation_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, stop: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    360\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 361\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_params\u001b[49m,\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    363\u001b[0m     }\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\langchain_community\\llms\\tongyi.py:234\u001b[0m, in \u001b[0;36mTongyi._default_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the default parameters for calling Tongyi Qwen API.\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m normal_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_p,\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdashscope_api_key,\n\u001b[0;32m    232\u001b[0m }\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormal_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'FieldInfo' object is not a mapping"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "from langchain import OpenAI\n",
    "\n",
    "# 设置API密钥\n",
    "DASHSCOPE_API_KEY = \"你的API密钥\"  # 替换为你的API密钥\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "\n",
    "# 创建一个OpenAI客户端实例\n",
    "openai_client = OpenAI(api_key=DASHSCOPE_API_KEY)\n",
    "\n",
    "# 实例化Tongyi类，并传递client参数\n",
    "# 注意：以下代码可能需要根据实际情况进行调整\n",
    "llm = Tongyi(model_name=\"qwen-max\", client=1)\n",
    "\n",
    "# 使用Tongyi类生成文本\n",
    "prompt = \"Translate the following English text to Chinese: 'Hello, how are you?'\"\n",
    "stop = [\"。\"]\n",
    "\n",
    "# 假设Tongyi类有一个方法来生成文本\n",
    "result = llm.generate([prompt], stop=stop)\n",
    "\n",
    "# 输出生成的文本\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
