{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 朴素贝叶斯分类法\n",
    "\n",
    "朴素贝叶斯方法是一类基于贝叶斯公式的监督学习方法，它假定特征之间两两独立(朴素)。对于一个目标分类变量$y$与$n$个特征$x_1,\\cdots,x_n$来说，有如下的贝叶斯公式：\n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
    "\n",
    "大家注意：左边的式子就是给定特征的取值，求分类变量的概率分布，这就是我们希望计算目标。而右边的三项分别是\n",
    "* 分类变量$y$自身的概率分布 $P(y)$.\n",
    "    * 这一项比较容易通过样本来估计，比如$y$是离散分类，我们可以直接统计各个分类的频率\n",
    "* 特征$\\{x_1,\\dots,x_n\\}$的联合概率分布 $P(x_1, \\dots, x_n)$.\n",
    "    * 这一项不需要计算，因为给定这一项与$y$没有关系，而且自己单独呆在在分母上。于是$$P(y \\mid x_1, \\dots, x_n)\\propto P(y) P(x_1, \\dots x_n \\mid y)$$\n",
    "* 特征$\\{x_1,\\dots,x_n\\}$在$y$条件下的联合概率分布 $P(x_1, \\dots, x_n\\mid y)$.\n",
    "    * 这一项必须计算，而且当特征较多时候，收数据的限制联合分布一般很难计算。\n",
    "    * 而朴素贝叶斯方法，就是在特殊假设下对这一项进行简化的算法。\n",
    "\n",
    "如果我们假定在$y$的条件下$\\{x_1,\\dots,x_n\\}$是两两独立的随机变量。那么对于任何$i,j$,都有$P(x_i, x_j\\mid y) = P(x_i\\mid y)\\cdot P(x_j\\mid y)$于是上面的条件联合分布就可以简化为:\n",
    "$$P(x_1, \\dots, x_n\\mid y) = \\prod\\limits_{i=1}^nP(x_i\\mid y)$$\n",
    "\n",
    "而这其中单独的$P(x_i\\mid y)$也相对容易通过样本来进行估计，我们可以对$x_i$的分布类型进行建模，然后利用普通的参数估计方法来研究。\n",
    "\n",
    "不同的特征$P(x_i\\mid y)$可能对应于不同类型的概率分布，而每种类型概率分布都对应一个朴素贝叶斯分类方法：\n",
    "* $x$服从高斯分布时：  高斯朴素贝叶斯\n",
    "* $x$服从多项分布时：  多项分布朴素贝叶斯\n",
    "* $x$服从伯努利分布时：伯努利朴素贝叶斯\n",
    "\n",
    "下面我们给一个高斯朴素贝叶斯的例子(数据和代码来自[sklearn 手册](http://scikit-learn.org/stable/modules/naive_bayes.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# iris(鸢尾花)分类数据集\n",
    "iris 数据集是一个根据iris花的萼片长度，萼片宽度，花瓣长度，花瓣宽度来对花进行分类的数据。\n",
    "* $x_1,\\dots,x_4$四个实数分别对应于上诉四种特征。\n",
    "* $y$ 是一个正整数，对应于花的分类。\n",
    "我们的目的是通过一部分数据集进行训练，让我们能够利用iris花的这几项特征来实现花的自动分类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入iris数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davy/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "四个特征数据构成一个m行4列的矩阵\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.7 3.1 5.6 2.4]]\n",
      "分类数据构成一个m行1列的向量\n",
      "[0 0 0 1 1 2 2 2]\n",
      "将数据分为训练数据(x_train,y_train)和测试数据(x_test,y_test)\n"
     ]
    }
   ],
   "source": [
    "#载入iris数据\n",
    "print ('载入iris数据')\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print ('四个特征数据构成一个m行4列的矩阵')\n",
    "print (iris.data[::20])\n",
    "\n",
    "print ('分类数据构成一个m行1列的向量')\n",
    "print (iris.target[::20])\n",
    "\n",
    "print ('将数据分为训练数据(x_train,y_train)和测试数据(x_test,y_test)')\n",
    "X_train = iris.data[::2]\n",
    "y_train = iris.target[::2]\n",
    "\n",
    "X_test = iris.data[1::2]\n",
    "y_test = iris.target[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备高斯贝叶斯分类器\n"
     ]
    }
   ],
   "source": [
    "#准备高斯贝叶斯分类器\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "print ('准备高斯贝叶斯分类器')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练模型\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "gnb.fit(X_train, y_train)\n",
    "print ('训练模型')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "利用测试特征X_test,预测得出y_pred, 并与y_test进行比较\n",
      "\n",
      "75 个数据点中，预测错误的一共有 : 3\n"
     ]
    }
   ],
   "source": [
    "#利用测试特征X_test,预测得出y_pred, 并与y_test进行比较\n",
    "print ('利用测试特征X_test,预测得出y_pred, 并与y_test进行比较\\n')\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"%d 个数据点中，预测错误的一共有 : %d\"%(X_test.shape[0],(y_test != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自动分类结果： [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "真实分类结果 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print ('自动分类结果：', y_pred)\n",
    "\n",
    "\n",
    "print ('真实分类结果', y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
